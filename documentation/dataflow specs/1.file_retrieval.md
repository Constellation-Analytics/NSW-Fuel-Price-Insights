# Module Spec: 1.file_retrieval.py

## 1. Module Overview
- **Name / ID:** `1.file_retrieval.py`  
- **Purpose:** Retrieves the latest monthly Fuel Check dataset from NSW Government, converts it to CSV, commits it to GitHub, and updates runtime configuration (`config.json`).  
- **Author / Date:** Paul – 21 Jan 2026  

## 2. Upstream Dependencies
- Triggered by orchestrator module  
- GitHub Actions environment  
- Environment variables:
  - `GITHUB_TOKEN`
  - `GITHUB_REPOSITORY`
- `config.json` – runtime configuration  

## 3. Downstream Dependencies
- Data transformation module (`2.transform_data.py`)  
- Retention or update modules depending on workflow  

## 4. Inputs / Sources
- **Web source:** NSW Fuel Check dataset page  
  - `https://data.nsw.gov.au/data/dataset/fuel-check`
- **Config file:** `config.json`  
  - `next_file_date`  
  - `latest_file`  
  - `last_transformation`
- **Command-line arguments:**  
  - `--log-file` from orchestrator
- **System time:** Used to determine current month and idempotency  

## 5. Outputs
- Monthly fuel data file saved as CSV  
  - Path: `data and logs/`  
  - Naming: `fuelcheck_<mon><year>.csv`
- Updated `config.json` with:
  - `latest_file`  
  - `next_file_date`
- Git commits containing:
  - New data file  
  - Updated config file
- Workflow logs written to orchestrator-provided log file  

## 6. Logic / Steps
1. Initialise module logging using orchestrator-provided log file  
2. Load `config.json`  
3. Determine:
   - `latest_file` – last processed file  
   - `next_file_date` – next expected file  
   - `current_monthyear` – current month marker for idempotency  
4. Connect to Fuel Check dataset webpage using `requests`  
5. Parse HTML with `BeautifulSoup` to identify `.csv` or `.xlsx` download links for `next_file_date`  
6. Conditional exits (`sys.exit(10)`):
   - Exit if current month has already been processed  
   - Exit if expected file is not yet available  
   - Exit if `latest_file` has not yet been transformed (`last_transformation` check)  
7. Download the first matching file  
8. Load file into pandas DataFrame based on extension (`.csv` or `.xlsx`)  
9. Convert and save data as CSV to `data and logs/`  
10. Commit and push CSV file to GitHub using `push_file_to_repo`  
11. Update `config.json` with new `latest_file` and incremented `next_file_date`  
12. Commit and push updated config file  

## 7. Conditional Checks
1. **Duplicate processing**
   - If `current_monthyear == next_file_date` → exit without error
2. **File availability**
   - If no matching download link found → exit without error
3. **Pending transformation**
   - If `latest_file != last_transformation` → exit without error
4. **File format**
   - Supports `.csv` and `.xlsx` only

## 8. Error Handling & Logging
- Log all major steps, decisions, and URLs accessed  
- Git operations wrapped in `try/except`  
- Exceptions logged with stack trace  
- Non-critical exits use `sys.exit(10)` to avoid orchestrator failure  
- Critical failures re-raised for orchestrator handling  
- Logger includes timestamp, severity, and module identifier
